{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC-E7851 Computational User Interface Design\n",
    "\n",
    "# Bandits (07.12.2018)\n",
    "### Kashyap Todi (www.kashyaptodi.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Bandit\n",
    "\n",
    "We start by defining a Bandit.\n",
    "\n",
    "A bandit has $n$ arms.<br/>\n",
    "Each arm has a reward probability $\\theta$.<br/>\n",
    "When we pull an arm $i$, the bandit returns a reward with corresponding probability $i_\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Bandit instance with 3 arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Generic Solver\n",
    "\n",
    "A generic Bandit solver consists of:\n",
    "1. bandit: A Bandit object\n",
    "2. counts: Number of times each arm has been pulled\n",
    "3. actions: A History of actions taken (arms pulled)\n",
    "4. regret: Cumulative regret until current time step\n",
    "5. regrets: A history of cumulative regrets\n",
    "\n",
    "A solver must specify the steps taken during a single time step (`run_one_step`)\n",
    "\n",
    "A solver can be run $num\\ steps$ times, to calculate the cumulative regret and optionally the estimated $\\theta$s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an Experiment\n",
    "Let us now define an experiment to run the solver for n trials with m iterations each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Solvers\n",
    "\n",
    "### 1. Explore-Only:\n",
    "First, let's write a random solver, that randomly explores at every iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploit-Only:\n",
    "Next, let's write a Greedy solver, that exploits a pre-determined arm at every iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. $\\epsilon$-Greedy:\n",
    " \n",
    "We can explore random arms with a fixed probability ($\\epsilon$), while exploiting the best found arm otherwise.\n",
    " \n",
    "After each time step, we obtain reward r for pulling arm i.<br/>\n",
    "We update the estimated theta for arm i based on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4. UCB1:\n",
    " \n",
    "The Upper Confident Bound solver prefers arms with stronger potential for optimal value.\n",
    "\n",
    "At each step, we pick the best arm $i$ to maximise the upper confidence bound\n",
    "\n",
    "$a_t^{UCB}= argmax_{a\\in A} \\hat{Q_t}(a) + \\hat{U_t}(a)$<br><br>\n",
    "$\\hat{U_t}(a) = \\sqrt{\\dfrac{2 \\log t}{2N_t(a)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 5. Thompson Sampling:\n",
    " \n",
    "The Thompson Sampling solver implements probability matching.\n",
    "\n",
    "For Bernoulli bandit, Q(a) follows a Beta distribution\n",
    "\n",
    "By default, $\\alpha$ and $\\beta$ are set to 1 (50% reward probability).<br>\n",
    "We can set initial $\\alpha$ and $\\beta$ based on our prior knowledge of reward probability.<br>\n",
    "\n",
    "After pulling an arm i, the $\\alpha$ and $\\beta$ for i is updated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test the solvers by running the experiment and printing the mean cumulative regret and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## In-class task 1: \n",
    "- Modify the bandit instance (add more arms, change $\\theta$s.\n",
    "- Change the target arm for Greedy.\n",
    "- Change $\\epsilon$ for $\\epsilon$-Greedy.\n",
    "- Specify strong prior for Thompson Sampling ( $\\alpha$ and $\\beta$ ).\n",
    "\n",
    "Observe and discuss how the results vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-class task 2:\n",
    "- For one trial, plot a comparative graph showing cumulative regrets over time for each solver.\n",
    "- Calculate *cumulative reward* over time for each solver, and construct the plot again.\n",
    "\n",
    "Discuss how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
